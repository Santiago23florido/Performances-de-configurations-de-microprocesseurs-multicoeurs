\section{Configuration and conclusion}
\subsection{Configuration CMP la plus efficace}
Se propose donc la sélection d’un microprocesseur \textbf{Cortex-A7 (ARM)}, avec une configuration à \textbf{8 threads}, car cette option offre un compromis pertinent entre le nombre de threads, le \emph{speedup} et l’IPC global observé. Ce choix est principalement justifié par le fait que, dans les conditions de l’application étudiée, l’exécution cesse rapidement d’être \emph{compute bound} pour devenir fortement contrainte par la mémoire ; dans ce contexte, l’emploi d’un microprocesseur A15 n’apporte pas d’amélioration significative. En effet, les résultats montrent non seulement que les \emph{speedups} obtenus avec les A15 pour une matrice de taille $M=128$ restent proches de ceux mesurés sur A7, mais aussi que, pour le même nombre de threads ($8$), les valeurs d’IPC global sont très similaires à celles de la configuration proposée. Par ailleurs, la configuration à $8$ threads est retenue de préférence à celle à $16$ threads, car l’on observe que, pour des tailles de matrice inférieures à $M=128$, le \emph{speedup} tend à saturer, notamment en raison des phénomènes déjà identifiés : défauts de cache et pénalités mémoire, surcoûts OpenMP, coûts de synchronisation, ainsi que la présence de sections linéaires non parallélisables du code qui limitent le gain global.


\subsection{speedup supra-linéaire}

Un \emph{speedup} supra-linéaire peut apparaître lorsque l’augmentation du nombre de threads améliore fortement l’utilisation des caches. En effet, les données peuvent être réparties entre plusieurs caches (notamment L1 et, selon l’architecture, L2), ce qui réduit la fréquence des accès à la mémoire principale et diminue la latence effective des lectures/écritures. Dans ce cas, le temps total peut baisser plus vite que la simple division du travail entre threads, car on gagne simultanément en parallélisme et en localité mémoire. Ce phénomène est généralement favorisé par des matrices de grande taille, des caches relativement petits (rendant la localité plus sensible), et un nombre de threads modéré, pour lequel l’augmentation de capacité de cache agrégée ne s’accompagne pas encore d’une contention excessive ni de surcoûts de synchronisation dominants.


\subsection{Conclusion}

Ce TP met en évidence l’impact du parallélisme et du type de cœur sur les performances. Les cœurs \emph{in-order} offrent un bon compromis pour concevoir des CMP efficaces en surface et en consommation, tandis que les cœurs \emph{out-of-order} (o3) permettent d’augmenter l’IPC grâce à une meilleure exploitation du parallélisme au niveau des instructions. Néanmoins, le \emph{speedup} observé reste souvent limité par la hiérarchie mémoire (contention, défauts de cache, latences) et par les surcoûts de synchronisation et de coordination imposés par l’exécution parallèle, ce qui empêche d’atteindre un gain proportionnel au nombre de threads.